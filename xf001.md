# DataFlare Actor模型改进方案

## 问题分析

通过对当前DataFlare框架的代码分析，我们发现数据流无法正常工作的主要问题：

1. **数据源与任务断连**：
   - `SourceActor`负责从连接器读取数据，但与`TaskActor`没有正确关联
   - 缺少明确的机制将数据从`SourceActor`传递到`TaskActor`系统中

2. **触发链不完整**：
   - 工作流启动时，虽然调用了`StartWorkflow`，但没有正确触发`SourceActor`的`StartExtraction`操作
   - `WorkflowActor`、`SourceActor`和`TaskActor`之间的协调机制不完善

3. **数据流通路阻塞**：
   - 虽然使用`AddDownstream`建立了源任务和目标任务的下游关系
   - 但源数据未能流入任务处理系统，导致目标文件未被创建

4. **异步执行无同步点**：
   - 工作流执行过快（日志显示0.00秒），没有等待数据处理完成
   - 缺少工作流完成的同步机制

## 改进方案

### 1. 建立SourceActor与TaskActor的关联机制

创建新的消息类型`ConnectToTask`将SourceActor与TaskActor关联：

```rust
/// 将SourceActor与TaskActor关联的消息
#[derive(Message)]
#[rtype(result = "()")]
pub struct ConnectToTask {
    /// TaskActor地址
    pub task_addr: Addr<TaskActor>,
    /// 任务ID
    pub task_id: String,
}
```

实现SourceActor对此消息的处理：

```rust
impl Handler<ConnectToTask> for SourceActor {
    type Result = ();
    
    fn handle(&mut self, msg: ConnectToTask, _ctx: &mut Self::Context) -> Self::Result {
        info!("SourceActor {} 与任务 {} 建立关联", self.id, msg.task_id);
        self.associated_task = Some((msg.task_id, msg.task_addr));
    }
}
```

### 2. 完善SourceActor的数据发送机制

修改SourceActor的StartExtraction处理器，确保读取的数据批次发送到关联的TaskActor：

```rust
// 在读取数据流并创建批次后
if let Some((task_id, task_addr)) = &self.associated_task {
    // 发送批次到关联的TaskActor
    debug!("SourceActor {} 发送批次 {} 到任务 {}", 
          self_id, batch_number, task_id);
    
    let send_result = task_addr.send(SendBatch {
        workflow_id: workflow_id.clone(),
        batch,
    }).await;
    
    if let Err(e) = send_result {
        error!("发送批次到任务时出错: {}", e);
        return Err(DataFlareError::Actor(
            format!("Error al enviar lote a tarea: {}", e)
        ));
    }
} else {
    error!("SourceActor {} 没有关联的任务，无法发送数据", self_id);
    return Err(DataFlareError::Actor(
        format!("SourceActor no tiene tarea asociada")
    ));
}
```

### 3. 完善WorkflowActor的启动流程

修改WorkflowActor的StartWorkflow处理器，确保正确触发源组件：

```rust
impl Handler<StartWorkflow> for WorkflowActor {
    type Result = Result<()>;

    fn handle(&mut self, _msg: StartWorkflow, ctx: &mut Self::Context) -> Self::Result {
        info!("Starting workflow {}", self.id);
        
        // 设置工作流状态为运行中
        self.status = ActorStatus::Running;
        self.stats.start_time = Some(chrono::Utc::now());
        self.start_time = Some(Instant::now());
        
        // 启动源任务并触发数据提取
        for (id, addr) in &self.tasks {
            if let Some(&TaskKind::Source) = self.task_kinds.get(id) {
                info!("Starting source task {}", id);
                
                // 1. 发送Resume消息
                addr.do_send(Resume {
                    workflow_id: self.id.clone(),
                });
                
                // 2. 发送StartExtraction消息以启动数据提取
                let source_config = if let Some(config) = &self.config {
                    // 从工作流配置中获取源配置
                    if let Some(source_id) = id.strip_prefix(&format!("{}.source.", self.id)) {
                        if let Some(sources) = &config.sources {
                            if let Some(source_config) = sources.get(source_id) {
                                source_config.config.clone()
                            } else {
                                serde_json::json!({})
                            }
                        } else {
                            serde_json::json!({})
                        }
                    } else {
                        serde_json::json!({})
                    }
                } else {
                    serde_json::json!({})
                };
                
                addr.do_send(StartExtraction {
                    workflow_id: self.id.clone(),
                    source_id: id.clone(),
                    config: serde_json::json!({
                        "batch_size": 1000,  // 批次大小
                        "timeout": 30000,   // 30秒超时
                        "max_batches": 0,   // 不限制批次数量
                        "source_config": source_config  // 源配置
                    }),
                    state: None,           // 无初始状态
                });
            }
        }
        
        // 同时启动SourceActor（如果存在）
        for (source_id, source_actor) in &self.source_actors {
            info!("Starting source actor {}", source_id);
            
            // 构建提取配置
            let extraction_config = serde_json::json!({
                "batch_size": 1000,
                "timeout": 30000,
                "max_batches": 0
            });
            
            // 发送StartExtraction消息
            source_actor.do_send(StartExtraction {
                workflow_id: self.id.clone(),
                source_id: source_id.clone(),
                config: extraction_config,
                state: None,
            });
        }
        
        Ok(())
    }
}
```

### 4. 实现工作流完成的同步机制

1. 创建工作流完成通知消息：

```rust
/// 工作流任务完成消息
#[derive(Message)]
#[rtype(result = "()")]
pub struct TaskCompleted {
    /// 工作流ID
    pub workflow_id: String,
    /// 任务ID
    pub task_id: String,
    /// 处理的记录数
    pub records_processed: usize,
}
```

2. 在WorkflowActor中跟踪任务完成状态：

```rust
impl Handler<TaskCompleted> for WorkflowActor {
    type Result = ();
    
    fn handle(&mut self, msg: TaskCompleted, _ctx: &mut Self::Context) -> Self::Result {
        info!("Task {} completed in workflow {}, processed {} records", 
             msg.task_id, msg.workflow_id, msg.records_processed);
        
        // 更新统计信息
        self.stats.records_processed += msg.records_processed;
        
        // 检查是否所有任务都已完成
        self.completed_tasks.insert(msg.task_id.clone());
        
        let all_tasks_completed = self.tasks.keys()
            .all(|id| self.completed_tasks.contains(id));
            
        if all_tasks_completed {
            info!("All tasks completed for workflow {}", self.id);
            // 标记工作流完成
            self.status = ActorStatus::Completed;
            self.stats.end_time = Some(chrono::Utc::now());
            
            // 广播工作流完成事件
            self.broadcast_progress(
                WorkflowPhase::Completed, 
                1.0, 
                &format!("Workflow {} completed", self.id)
            );
        }
    }
}
```

3. 修改TaskActor在处理完所有数据后发送完成通知：

```rust
// 在SendBatch处理器中，当检测到是最后一批数据时
if is_last_batch {
    // 通知工作流任务已完成
    if let Some(workflow_actor) = self.workflow_actor.as_ref() {
        workflow_actor.do_send(TaskCompleted {
            workflow_id: self.workflow_id.clone(),
            task_id: self.id.clone(),
            records_processed: self.stats.records_processed,
        });
    }
}
```

### 5. 在示例代码中正确关联组件

修改workflow_test.rs示例中的代码，确保组件正确关联：

```rust
// 创建Source Actor
let source_actor = SourceActor::new("csv-source", Box::new(source)).start();

// 创建源任务
let source_task = TaskActor::new("csv-source-task", TaskKind::Source).start();

// 创建目标任务
let dest_task = TaskActor::new("csv-dest-task", TaskKind::Destination).start();

// 关联SourceActor和源TaskActor
source_actor.do_send(ConnectToTask {
    task_addr: source_task.clone(),
    task_id: "csv-source-task".to_string(),
});

// 添加下游关系
source_task.do_send(AddDownstream {
    actor_addr: dest_task.clone(),
});
```

### 6. 添加工作流完成等待机制

在示例代码中添加工作流完成等待机制：

```rust
// 创建完成通知通道
let (tx, rx) = tokio::sync::oneshot::channel::<()>();
let tx_clone = tx.clone();

// 订阅工作流进度，在完成时发送通知
workflow_actor.do_send(SubscribeProgress {
    workflow_id: "test-workflow".to_string(),
    recipient: system.dispatcher().spawn(move |progress: WorkflowProgress| {
        if progress.phase == WorkflowPhase::Completed && progress.progress >= 0.99 {
            let _ = tx_clone.send(());
        }
        async {}
    }),
});

// 启动工作流
info!("启动工作流");
workflow_actor.send(StartWorkflow{}).await??;

// 等待工作流完成或超时
info!("等待工作流处理...");
match tokio::time::timeout(tokio::time::Duration::from_secs(60), rx).await {
    Ok(_) => info!("工作流已完成处理"),
    Err(_) => info!("等待工作流完成超时，可能仍在处理中"),
};
```

## 实施计划

1. **第一阶段**：实现SourceActor与TaskActor的关联机制
   - 新增ConnectToTask消息类型
   - 修改SourceActor添加关联任务字段
   - 实现ConnectToTask处理器

2. **第二阶段**：完善数据流传递机制
   - 修改SourceActor的StartExtraction处理器
   - 修改TaskActor的SendBatch处理器
   - 确保批次数据正确流转

3. **第三阶段**：实现工作流生命周期管理
   - 添加TaskCompleted消息
   - 实现WorkflowActor的任务完成跟踪
   - 添加工作流完成通知机制

4. **第四阶段**：更新示例代码和测试
   - 修改workflow_test.rs关联组件
   - 添加完成等待机制
   - 编写单元测试验证数据流

5. **第五阶段**：性能优化和监控
   - 优化批处理大小
   - 添加性能指标收集
   - 实现数据流监控可视化

## 预期成效

实施此改进方案后，我们预期达到以下效果：

1. 完整的数据流链路：数据将正确从源连接器流向目标连接器
2. 可靠的工作流执行：工作流将等待所有数据处理完成才结束
3. 明确的组件职责：各Actor职责更清晰，接口更一致
4. 更好的错误处理：异常情况有更完善的处理机制
5. 可观测性提升：通过统计和监控了解数据流情况

这些改进将使DataFlare框架成为一个更加健壮、可靠的数据处理系统，能够处理大规模数据流并提供清晰的执行状态反馈。 